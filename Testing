import datetime
import os
from dataclasses import dataclass

import pandas as pd
import numpy as np
from typing import Union

from syfi.syfi_utils import dateadd
from sylo.mdp import BPipeMarketDataProvider

ACCURACY = 1e-10

bbg_data_provider = BPipeMarketDataProvider()


@dataclass
class StratStops:
    stops_in_k: float = None
    trade_name: str = None
    start_date: datetime.date = None
    end_date: datetime.date = None
    pnl_folder: str = None
    bbg_function: str = None

    def __post_init__(self):
        self.data = self.get_pnl_series()

    def get_pnl_series(self) -> pd.DataFrame:
        assert self.trade_name is not None, "can't find trade name"
        assert self.pnl_folder is not None, "can't find folder name"

        file_location: str = os.path.join(self.pnl_folder, self.trade_name + '.csv')
        data = pd.read_csv(file_location, header=[0], index_col=0, parse_dates=True, dayfirst=True).dropna(how='all')

        if (self.start_date is not None) and (self.end_date is not None):
            return data.loc[self.start_date:self.end_date, "PV Live"]

        return data[['PV Live']]

    def find_peak_pnl_date(self,
                           column_name: str) -> datetime.date:
        data = self.get_pnl_series()
        return data[column_name].idxmax().to_pydatetime().date()

    def find_peak_pnl(self,
                      column_name: str) -> float:
        data = self.get_pnl_series()
        return data.loc[data[column_name].idxmax()][column_name]

    def calc_stop_level(self, fast_ma_window: int = 5,
                        slow_ma_window: int = 50,
                        slope_window: int = 10,
                        non_neg_stop_flag: bool = True,
                        return_df: bool = False,
                        add_init_buffer: bool = False,
                        init_buffer_pct: float = 0) -> Union[np.ndarray, pd.DataFrame]:
        df = self.data.copy(deep=True)

        if isinstance(df.index[0], datetime.datetime):
            df.index = list(map(lambda x: x.date(), df.index))

        BIG = 10e10
        TINY = 10e-8

        if add_init_buffer:
            assert (init_buffer_pct >= -ACCURACY) and (init_buffer_pct <= 1 + ACCURACY), \
                "init_buffer_pct msut be in [0,1]"
            df.loc[dateadd(df.index[0], '-1d', True, 'HKD')] = init_buffer_pct * self.stops_in_k
            df = df.sort_index()

        fast_ma = df.rolling(window=fast_ma_window, min_periods=0).mean()
        slow_ma = df.rolling(window=slow_ma_window, min_periods=0).mean()

        if isinstance(fast_ma, pd.Series):
            fast_ma = fast_ma.to_frame("fast_ma")
        else:
            fast_ma.columns = ['fast_ma']
        if isinstance(slow_ma, pd.Series):
            slow_ma = slow_ma.to_frame("slow_ma")
        else:
            slow_ma.columns = ['slow_ma']

        slope = slow_ma - slow_ma.shift(slope_window)
        slope.iloc[:slope_window] = slow_ma.iloc[:slope_window] - slow_ma.iloc[0].values

        slope = slope / slope.cummax()
        running_max = fast_ma.cummax()
        drawdown = running_max - fast_ma

        max_drawdown = -BIG
        reset_id_list = []
        trough_id_list = []
        stop_level_list = []
        fast_ma_trough_list = []
        slow_ma_support_list = []
        slope_adj_list = []
        max_drawdown_id = 0

        index = df.index

        for i in range(len(drawdown)):
            if np.isnan(drawdown.iloc[i].values[0]):
                continue

            if drawdown.iloc[i].values[0] > max_drawdown:
                max_drawdown = drawdown.iloc[i].values[0]

                max_drawdown_id = i
            if i > 0 and drawdown.iloc[i - 1].values[0] > TINY > drawdown.iloc[i].values[0]:
                reset_id_list.append(i)
                trough_id_list.append(max_drawdown_id)
                blending_coeff = max(slope.iloc[max_drawdown_id].values[0], 0.0)
                lower_bound = min(slow_ma.iloc[max_drawdown_id].values[0], fast_ma.iloc[max_drawdown_id].values[0])
                upper_bound = max(slow_ma.iloc[max_drawdown_id].values[0], fast_ma.iloc[max_drawdown_id].values[0])
                stop_level = blending_coeff * lower_bound + (1 - blending_coeff) * upper_bound
                stop_level_list.append(stop_level)
                slow_ma_support_list.append(slow_ma.iloc[max_drawdown_id].values[0])
                fast_ma_trough_list.append(fast_ma.iloc[max_drawdown_id].values[0])
                slope_adj_list.append(blending_coeff)

                max_drawdown = -BIG

        if len(reset_id_list) == 0:
            fast_ma_level = fast_ma.iloc[-1].values[0]
            stop_level = self.stops_in_k
            pnl_trough = df.min()
            pnl_trough_date = pd.to_datetime(df.idxmin())
            slow_ma_support = ""
            slope_adj = ""
            high_watermark = df.max()
            high_watermark_date = pd.to_datetime(df.idxmax())
        else:
            fast_ma_level = fast_ma.iloc[-1].values[0]
            stop_level = np.max(stop_level_list[-1])
            pnl_trough = fast_ma_trough_list[-1]
            pnl_trough_date = pd.to_datetime(index[trough_id_list[-1]])
            slow_ma_support = slow_ma_support_list[-1]
            slope_adj = slope_adj_list[-1]
            high_watermark = df.max()
            high_watermark_date = pd.to_datetime(df.idxmax())

        if non_neg_stop_flag:
            stop_final = stop_level if stop_level > 0 else self.stops_in_k
        else:
            stop_final = stop_level

        if return_df:
            stop_level_series = pd.DataFrame(data=[np.nan] * len(df), columns=['stop_level'], index=index)
            stop_level_series.loc[index[0], 'stop_level'] = self.stops_in_k
            stop_level_series.loc[index[reset_id_list], 'stop_level'] = np.array(stop_level_list)
            stop_level_series = stop_level_series.fillna(method='ffill')
            stop_level_series = stop_level_series.cummax()

            if non_neg_stop_flag:
                stop_level_series = stop_level_series.applymap(lambda x: x if x > 0 else self.stops_in_k)

            result_df = pd.concat([df, fast_ma, slow_ma, stop_level_series], axis=1)
            result_df.columns = ['pv', 'fast_ma', 'slow_ma', 'stop_level']

            if add_init_buffer:
                return result_df.iloc[1:]
            else:
                return result_df
        else:
            stats_df = pd.Series(
                {"Fast MA": fast_ma_level,
                 "Stop Level": stop_final,
                 "PnL Trough": pnl_trough,
                 "PnL Trough Date": pnl_trough_date,
                 "High PnL": high_watermark,
                 "High PnL Date": high_watermark_date,
                 "Slow MA Support": slow_ma_support,
                 "Slope Adj": slope_adj,
                 }).to_frame().T

            return stats_df.values


if __name__ == "__main__":
    stop_obj = StratStops(stops_in_k=-500,
                          trade_name="sys_1",
                          pnl_folder=r'G:\BFAM_FO\Systematic\Data Storage\Strategy_Level_PnL\discretionary')
    test_df = stop_obj.calc_stop_level(fast_ma_window=1,
                                       slow_ma_window=5,
                                       slope_window=10,
                                       non_neg_stop_flag=True,
                                       return_df=True)
